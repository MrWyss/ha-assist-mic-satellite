substitutions:
  version: "v1.1.4"
  
  # Optional
  timer_sound_file: https://github.com/esphome/firmware/raw/main/voice-assistant/sounds/timer_finished.wav
  #silence_sound_file: https://github.com/MrWyss/ha-assist-mic-satellite/raw/main/code/esphome/media/sounds/5s_silent.wav
  #timer_sound_file: media-source://media_source/local/timer_finished.mp3
  #silence_sound_file: media-source://media_source/local/10-seconds-of-silence.mp3
  
  voice_assist_idle_phase_id: "1"
  voice_assist_listening_phase_id: "2"
  voice_assist_thinking_phase_id: "3"
  voice_assist_replying_phase_id: "4"
  voice_assist_not_ready_phase_id: "10"
  voice_assist_error_phase_id: "11"
  voice_assist_timer_finished_phase_id: "13"
  voice_assist_credits_phase_id: "42"
  voice_assist_status_phase_id: "99"

 
esphome:
  name: va-mic-sat-atoms3
  friendly_name: Voice Assistant Mic Satellite
  name_add_mac_suffix: true
  platformio_options:
    board_build.flash_mode: dio
    board_build.variant: m5stack-atoms3
  project: 
    name: va-mic-satellite.va-mic-satellite
    version: ${version}
  on_boot:
    priority: 600
    then:
      - script.execute: draw_display

esp32:
  board: esp32-s3-devkitc-1
  variant: esp32s3
  flash_size: 8MB
  framework:
    type: esp-idf
    sdkconfig_options:
      CONFIG_ESP32S3_DEFAULT_CPU_FREQ_240: "y"
      #CONFIG_SPIRAM_ALLOW_STACK_EXTERNAL_MEMORY: "y"
      #CONFIG_ESP32S3_DATA_CACHE_64KB: "y"
      #CONFIG_ESP32S3_DATA_CACHE_LINE_64B: "y"
      #CONFIG_ESP32_S3_BOX_BOARD: "y"

wifi:
  ap: {}
  on_connect:
    - script.execute: draw_display
  on_disconnect:
    - script.execute: draw_display

# Enable logging
logger:
  level: DEBUG

# Enable Home Assistant API
api:
  on_client_connected: 
    then:
      - if:
          condition:
            lambda: return id(init_in_progress);
          then:
            - lambda: id(init_in_progress) = false;
            - script.execute: draw_display

ota:
  - platform: esphome
    id: ota_esphome
  - platform: http_request
    id: ota_http_request

http_request:
  buffer_size_rx : 1024
  buffer_size_tx : 1024


update:
  - platform: http_request
    name: None
    id: update_http_request
    source: https://mrwyss.github.io/ha-assist-mic-satellite/firmware/manifest.json

captive_portal:

dashboard_import:
  package_import_url: github://MrWyss/ha-assist-mic-satellite/code/esphome/va-mic-sat-atoms3.yaml@main                   
  import_full_config: true

improv_serial:

# Disable in favor of memory
#esp32_improv:
#  authorizer: none

web_server:

globals:
  - id: contributors
    type: std::vector<std::string>
    initial_value: |-
      {
        "Nabu Casa &", 
        "Home Assistant",
        "HA Community", 
        "***********", 
        "Your Name could be", 
        "burned in to", 
        "Firmware here", 
      }
  
  - id: init_in_progress
    type: bool
    restore_value: false
    initial_value: "true"

  - id: voice_assistant_phase
    type: int
    restore_value: false
    initial_value: ${voice_assist_not_ready_phase_id}
 
  - id: timers_text
    type: std::string
    restore_value: false
    initial_value: ""

  - id: lines_array
    type: std::vector<std::string>

  - id: line_spacing
    type: int
    restore_value: false
    initial_value: '12'

  - id: max_line_length
    type: int
    restore_value: false
    initial_value: '20'
  
  - id: max_line_count
    type: int
    restore_value: false
    initial_value: '4'

  - id: display_duration
    type: int
    restore_value: false
    initial_value: '8000'

button:
  - platform: safe_mode
    id: button_safe_mode
    name: Safe Mode Boot
    entity_category: diagnostic

  - platform: factory_reset
    id: factory_reset_btn
    name: Factory reset
    entity_category: diagnostic
    
  # TODO: Remove before launch, added for testing/development
  - platform: template
    name: Check for update
    entity_category: diagnostic
    on_press:
      - component.update: update_http_request

#G41=Button
binary_sensor:
  - platform: status
    name: "Node Status"
    id: system_status
    entity_category: diagnostic
  
  - platform: gpio
    id: display_button
    name: Display Button
    entity_category: diagnostic
    filters:
      - delayed_off: 10ms
    pin:
      number: GPIO41
      inverted: true
      mode:
        input: true
        pullup: true
    on_multi_click:
      - timing: # Single Click
          - ON for 40ms to 400ms
          - OFF for at least 330ms
        then:
          - logger.log: Single Click
          - if:
              condition:
                switch.is_on: timer_ringing
              then:
                switch.turn_off: timer_ringing
      
      - timing: # Double Click
          - ON for 20ms to 400ms
          - OFF for 20ms to 300ms
          - ON for 20ms to 400ms
          - OFF for at least 300ms
        then:
          - logger.log: Double Click
          - lambda: |-
              id(voice_assistant_phase) = ${voice_assist_status_phase_id};
          - script.execute: draw_display
          - wait_until:
              condition:
                binary_sensor.is_on: display_button
              timeout: 20s
          - lambda: |-
              id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
          - script.execute: draw_display

      - timing: # Triple Click
          - ON for 20ms to 400ms
          - OFF for 20ms to 300ms
          - ON for 20ms to 400ms
          - OFF for 20ms to 300ms
          - ON for 20ms to 400ms
          - OFF for at least 300ms
        then:
          - logger.log: Triple Click
          - lambda: |-
              id(voice_assistant_phase) = ${voice_assist_credits_phase_id};
          - script.execute: draw_display
          - wait_until:
              condition:
                binary_sensor.is_on: display_button
              timeout: 20s
          - lambda: |-
              id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
          - script.execute: draw_display

      - timing: # Hold
          - ON for at least 700ms
        then:
          - logger.log: Hold
          - switch.toggle: mute
      
      - timing: # Long Hold
          - ON for at least 10s
        then:
          - button.press: factory_reset_btn

image:
  - file: https://github.com/MrWyss/ha-assist-mic-satellite/raw/main/code/esphome/media/animation/micsatellite_error.png
    id: micsatellite_error
    resize: 128x128
    type: RGB24
    use_transparency: true
  
  - file: https://github.com/MrWyss/ha-assist-mic-satellite/raw/main/code/esphome/media/animation/micsatellite_idle.png
    id: micsatellite_idle
    resize: 128x128
    type: RGB24
    use_transparency: true
  
  - file: https://github.com/MrWyss/ha-assist-mic-satellite/raw/main/code/esphome/media/animation/micsatellite_idle_mute.png
    id: micsatellite_idle_mute
    resize: 128x128
    type: RGB24
    use_transparency: true

  - file: https://github.com/MrWyss/ha-assist-mic-satellite/raw/main/code/esphome/media/animation/micsatellite_listening.png
    id: micsatellite_listening
    resize: 128x128
    type: RGB24
    use_transparency: true
  
  - file: https://github.com/MrWyss/ha-assist-mic-satellite/raw/main/code/esphome/media/animation/micsatellite_thinking.png
    id: micsatellite_thinking
    resize: 128x128
    type: RGB24
    use_transparency: true
  
  - file: https://github.com/MrWyss/ha-assist-mic-satellite/raw/main/code/esphome/media/animation/micsatellite_replying.png
    id: micsatellite_replying
    resize: 128x128
    type: RGB24
    use_transparency: true
  
  - file: https://raw.githubusercontent.com/MrWyss/ha-assist-mic-satellite/main/code/esphome/media/animation/MicSatellite.png
    id: micsatellite_small
    resize: 48x48
    type: RGB24
    use_transparency: true

font:
  - id: font_request
    file:
      type: gfonts
      family: Inconsolata
      weight: 300
      #italic: true
    glyphsets: 
      - GF_Latin_Core
    size: 12
    bpp: 4
  
  - id: font_response
    file:
      type: gfonts
      family: Inconsolata
      weight: 500
    glyphsets: 
      - GF_Latin_Core
    size: 12
    bpp: 4

  - id: font_status
    file:
      type: gfonts
      family: Inconsolata
      weight: 500
    glyphsets: 
      - GF_Latin_Core
    size: 12
    bpp: 4

text_sensor:
  - id: text_request
    platform: template
    on_value:
      lambda: |-
        if(id(text_request).state.length()>255) {
          std::string name = id(text_request).state.c_str();
          std::string truncated = esphome::str_truncate(name.c_str(),252);
          id(text_request).state = (truncated+"...").c_str();
        }

  - id: text_response
    platform: template
    on_value:
      lambda: |-
        if(id(text_response).state.length()>255) {
          std::string name = id(text_response).state.c_str();
          std::string truncated = esphome::str_truncate(name.c_str(),252);
          id(text_response).state = (truncated+"...").c_str();
        }

  - id: project_version
    platform: template
    update_interval: 1h
    lambda: |-
      return {"${version}"};

  - platform: wifi_info
    ip_address:
      id: ip_address
    ssid:
      id: wifi_ssid
    mac_address:
      id: wifi_mac_address

debug: 

sensor: 
  - platform: debug
    free:
      id: startup_memory_free

text:      
  - platform: template
    id: mp_id
    mode: text
    name: Media Player Entity id
    entity_category: config
    optimistic: true
    restore_value: true
    initial_value: media_player.office
    on_value:
      then:
        - logger.log:
            format: "%s"
            args: ["x.c_str()"]
        

color:
  - id: timer_color
    hex: "E35A10"
  - id: bg_black_color
    hex: "000000"
  - id: request_color
    hex: "FFFFFF"
  - id: response_color
    hex: "FFEA00"
  - id: error_color
    hex: "FB3B02"
  - id: init_color
    hex: "E35A10"
  - id: status_color
    hex: "FFB000"
  
spi:
  clk_pin: 17
  mosi_pin: 21

output:
  - platform: ledc
    pin: 16
    id: backlight_pwm
    frequency: 500Hz # according to the M5 Stack documentation
    min_power: 0.14 # tried: 0.25, 0.28, 0.2, 0.1, 0.16 -> flickering worse
    max_power: 1
    zero_means_zero: true

light:
  - platform: monochromatic
    output: backlight_pwm
    name: "Display Brightness"
    icon: "mdi:brightness-6"
    id: back_light
    restore_mode: RESTORE_AND_ON

switch:
  - platform: template
    name: Display conversation
    id: display_conversation
    optimistic: true
    restore_mode: RESTORE_DEFAULT_ON

  - platform: template
    name: Mute
    id: mute
    icon: "mdi:microphone-off"
    optimistic: true
    restore_mode: RESTORE_DEFAULT_OFF
    on_turn_off:
      - if:
          condition:
            lambda: return !id(init_in_progress);
          then:
            - lambda: id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
            - if:
                condition:
                  not:
                    - micro_wake_word.is_running
                then:
                  - micro_wake_word.start
            - script.execute: draw_display
    on_turn_on:
      - if:
          condition:
            lambda: return !id(init_in_progress);
          then:
            - micro_wake_word.stop
            - script.execute: draw_display

  - platform: template
    id: timer_ringing
    optimistic: true
    internal: true
    restore_mode: ALWAYS_OFF
    on_turn_on:
      - delay: 5min
      - switch.turn_off: timer_ringing

i2s_audio:
  - id: i2s_in # For microphone
    i2s_lrclk_pin: GPIO5  #WS 
    i2s_bclk_pin: GPIO6 #SCK

microphone:
  - platform: i2s_audio
    i2s_audio_id: i2s_in
    id: va_mic
    i2s_din_pin: GPIO7 #SD
    adc_type: external
    channel: left
    pdm: false
    bits_per_sample: 32bit

micro_wake_word:
  vad:
  models:
    - model: okay_nabu
  on_wake_word_detected:
    - voice_assistant.start: 
        wake_word: !lambda return wake_word; 

voice_assistant:
  id: va
  microphone: va_mic
  noise_suppression_level: 2
  auto_gain: 31dBFS
  volume_multiplier: 2.0
  use_wake_word: false



  on_client_connected: # An automation to perform when Home Assistant has connected and is waiting for Voice Assistant commands.
    #- logger.log: "on_client_connected"
    - if:
        condition:
          switch.is_off: mute
        then:
          - delay: 2s
          - micro_wake_word.start
        else:
          - micro_wake_word.stop
    - lambda: id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
    - lambda: id(init_in_progress) = false;
    - script.execute: draw_display
  
  #on_start: # An automation to perform when the assist pipeline is started.
  #  - logger.log: "on_start"

  # not called with open wake word
  #on_wake_word_detected: # An automation to perform when the assist pipeline has detected a wake word.
  #  - logger.log: "on_wake_word_detected"
  
  on_listening: # An automation to perform when the voice assistant microphone starts listening.
    #- logger.log: "on_listening"
    - homeassistant.service:
        service: media_player.volume_mute
        data:
          entity_id: !lambda 'return id(mp_id).state.c_str();'
          is_volume_muted: "true"
    - lambda: id(voice_assistant_phase) = ${voice_assist_listening_phase_id};
    - text_sensor.template.publish:
        id: text_request
        state: "..."
    - text_sensor.template.publish:
        id: text_response
        state: "..."
    - script.execute: draw_display

  #on_stt_vad_start: # An automation to perform when voice activity detection starts speech-to-text processing.
  #  - logger.log: "on_stt_vad_start"

  #on_stt_vad_end: # An automation to perform when voice activity detection ends speech-to-text processing.
  #  - logger.log: "on_stt_vad_end"

  on_stt_end: # An automation to perform when the voice assistant has finished speech-to-text. The resulting text is available to
    #- logger.log: "on_stt_end"
    - text_sensor.template.publish:
        id: text_request
        state: !lambda return x;
    - script.execute: draw_display

  #on_intent_start: # An automation to perform when intent processing starts.
  #  - logger.log: "on_intent_start"
  
  on_intent_end: # An automation to perform when intent processing ends.
    - logger.log: "on_intent_end"
    - homeassistant.service:
        service: media_player.volume_mute
        data:
          entity_id: !lambda 'return id(mp_id).state.c_str();'
          is_volume_muted: "false"
  
  on_tts_start: # An automation to perform when the voice assistant has started text-to-speech. The text to be spoken is available to automations as the variable x.
    #- logger.log: "on_tts_start"
    - text_sensor.template.publish:
        id: text_response
        state: !lambda return x;
    - lambda: id(voice_assistant_phase) = ${voice_assist_replying_phase_id};
    - script.execute: draw_display
   
  on_tts_end: # An automation to perform when the voice assistant has finished text-to-speech. A URL containing the audio response is available to automations as the variable x.
    #- logger.log: "on_tts_end"
    - logger.log:
        format: "Media Player id: %s"
        args: ["id(mp_id).state.c_str()"]
    - homeassistant.service:
        service: media_player.play_media
        data:
          entity_id: !lambda 'return id(mp_id).state.c_str();'
          media_content_id: !lambda 'return x.c_str();'
          media_content_type: "music"
          announce: "true"
      
  on_end: # An automation to perform when the voice assistant is finished all tasks.
    #- logger.log: "on_end"
    - wait_until:
        not:
          voice_assistant.is_running:
    - delay: !lambda 'return id(display_duration);'
    - if:
        condition:
          switch.is_off: mute
        then:
          - micro_wake_word.start # TODO: Find out why this is needed
    - lambda: id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
    - script.execute: draw_display
  
  # Speaker Needed
  #on_tts_stream_start: # An automation to perform when audio stream (voice response) playback starts. Requires speaker to be configured.
  #  - logger.log: "on_tts_stream_start"
 
  #on_tts_stream_end: # An automation to perform when audio stream (voice response) playback ends. Requires speaker to be configured.
  #  - logger.log: "on_tts_stream_start"


  #on_idle: # An automation to perform when the voice assistant is idle (no other actions/states are in progress).
  #  - logger.log: "on_idle"

  on_error: # An automation to perform when the voice assistant has encountered an error. The error code and message are available to automations as the variables code and message.
    #- logger.log: "on_error"
    - if:
        condition:
          lambda: return !id(init_in_progress);
        then:
          - homeassistant.service:
              service: media_player.volume_mute
              data:
                entity_id: !lambda 'return id(mp_id).state.c_str();'
                is_volume_muted: "false"
          - lambda: id(voice_assistant_phase) = ${voice_assist_error_phase_id};
          - script.execute: draw_display
          - delay: 2s
          - lambda: id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
          - script.execute: draw_display

  on_client_disconnected : # An automation to perform when Home Assistant disconnects from the Voice Assistant.
    #- logger.log: "on_client_disconnected"
    - lambda: id(voice_assistant_phase) = ${voice_assist_not_ready_phase_id};
    - script.execute: draw_display
    - voice_assistant.stop
    - micro_wake_word.stop

  on_timer_started: # An automation to perform when a voice assistant timer has finished. The timer is available as timer of type
    #- logger.log: "on_timer_started"
    - lambda: |-
        ESP_LOGD("main", "Timer started: ID: %s, Name: %s",timer.id.c_str(), timer.name.c_str());
  
  on_timer_cancelled: # An automation to perform when a voice assistant timer has been cancelled. The timer is available as timer of type voice_assistant::Timer.
    #- logger.log: "on_timer_cancelled"
    - lambda: |-
        ESP_LOGD("main", "Timer cancelled: ID: %s, Name: %s",timer.id.c_str(), timer.name.c_str());
        id(timers_text).clear();
    - switch.turn_off: timer_ringing
    - lambda: id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
    - script.execute: draw_display

  on_timer_updated: # An automation to perform when a voice assistant timer has been updated (paused/resumed/duration changed). The timer is available as timer of type voice_assistant::Timer.
    #- logger.log: "on_timer_updated"
    - lambda: |-
        ESP_LOGD("main", "Timer updated: ID: %s, Name: %s",timer.id.c_str(), timer.name.c_str());

  on_timer_tick: # An automation to perform when the voice assistant timers tick is triggered. This is called every 1 second while there are timers on this device. The timers are available as timers which is a std::vector (array) of type voice_assistant::Timer.
    #- logger.log: "on_timer_tick"
    - lambda: |-
        auto pad_zero = [](int num) {
          return (num < 10 ? "0" : "") + std::to_string(num);
        };
        id(timers_text).clear();
        for (const auto& timer : timers) {
          int hours = timer.seconds_left / 3600;
          int minutes = (timer.seconds_left % 3600) / 60;
          int seconds = timer.seconds_left % 60;
          std::string time_str = pad_zero(hours) + ":" +
                                 pad_zero(minutes) + ":" +
                                 pad_zero(seconds);
          std::string name = timer.name.empty() ? "none" : timer.name;

          id(timers_text) += name + ": " + time_str + "~";
          ESP_LOGD("main", "Timer tick: ID: %s, Name: %s, Remaining: %s",timer.id.c_str(), timer.name.c_str(), time_str.c_str());
        }

  on_timer_finished: # An automation to perform when a voice assistant timer has finished. The timer is available as timer of type voice_assistant::Timer.
    #- logger.log: "on_timer_finished"
    - text_sensor.template.publish:
        id: text_response
        state: !lambda |-
          std::string timer_name = std::string(timer.name.c_str()) + " finished";
          return timer_name;
    - lambda: |-
        ESP_LOGD("main", "Timer finished: Name: %s", timer.name.c_str());
        id(timers_text).clear();     
    - script.execute: play_alarm

display:
  - platform: ili9xxx
    model: ST7789V
    id: s3_lcd
    cs_pin: 15
    dc_pin: 33
    reset_pin: 34
    rotation: 180
    invert_colors: true
    update_interval: 1s
    dimensions:
      height: 128
      width: 128
      offset_height: 1
      offset_width: 2
    pages:
      - id: idle_page
        lambda: |-
          it.fill(id(bg_black_color));
          if (id(mute).state) {
            it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_idle_mute), ImageAlign::CENTER);
          } else {
            it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_idle), ImageAlign::CENTER);
          }
          if (!id(timers_text).empty()) {
            char *text = strdup(id(timers_text).c_str());
            char *line = strtok(text, "~");
            int y_offset = 0;  // Start from the top
            while (line != nullptr) {
              it.printf(0, y_offset, id(font_response), id(timer_color), TextAlign::TOP_LEFT, "%s", line);
              y_offset += 12;  // Adjust the vertical position for each line
              line = strtok(nullptr, "~");
            }
            free(text);
          }

      - id: listening_page
        lambda: |-
          it.fill(id(bg_black_color));
          it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_listening), ImageAlign::CENTER);
      
      - id: thinking_page
        lambda: |-
          it.fill(id(bg_black_color));
          it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_thinking), ImageAlign::CENTER);

          if (id(display_conversation).state) {
            //std::string text = id(text_request).state.c_str();
            id(convertto_multiline)->execute(id(text_request).state.c_str());
      
            int y = 0;
            for (const auto& line : id(lines_array)) {
              it.printf(5, y, id(font_request), id(request_color), TextAlign::TOP_LEFT, "%s", line.c_str());
              y += id(line_spacing); // Adjust this value if needed
            }
          }
      
      - id: replying_page
        lambda: |-
          it.fill(id(bg_black_color));
          it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_replying), ImageAlign::CENTER);
          if (id(display_conversation).state) {
            // Multi-line request
            id(convertto_multiline)->execute(id(text_request).state.c_str());
      
            int y = 0;
            int request_lines_count = 0;
            for (const auto& line : id(lines_array)) {
              it.printf(5, y, id(font_request), id(request_color), TextAlign::TOP_LEFT, "%s", line.c_str());
              y += id(line_spacing); // Adjust this value if needed
              request_lines_count++;
            }
      
            // Calculate the offset for the response
            int response_offset = request_lines_count * id(line_spacing);
      
            // Multi-line response
            id(convertto_multiline)->execute(id(text_response).state.c_str());
      
            y = response_offset;
            for (const auto& line : id(lines_array)) {
              it.printf(128, y, id(font_response), id(response_color), TextAlign::TOP_RIGHT, "%s", line.c_str());
              y += id(line_spacing); // Adjust this value if needed
            }
          }
      
      - id: error_page
        lambda: |-
          it.fill(id(bg_black_color));
          it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_error), ImageAlign::CENTER);
          int y_offset = it.get_height() - 12; 
          it.printf(64, y_offset, id(font_response), id(error_color), TextAlign::CENTER, "%s", "Error");
      
      - id: no_ha_page
        lambda: |-
          it.fill(id(bg_black_color));
          it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_error), ImageAlign::CENTER);
          int y_offset = it.get_height() - 12; 
          it.printf(64, y_offset, id(font_response), id(error_color), TextAlign::CENTER, "%s", "No Home Assistant");
      
      - id: timer_finished_page
        lambda: |-
          it.fill(id(bg_black_color));
          it.image((it.get_width() / 2), (it.get_height() / 2), id(micsatellite_replying), ImageAlign::CENTER);
          it.printf(64, 5, id(font_response), id(timer_color), TextAlign::CENTER, "%s", id(text_response).state.c_str());

      - id: initializing_page
        lambda: |-
            it.fill(id(bg_black_color));
            for (int i = 0; i < 10; i++) {
                int x = rand() % it.get_width();
                int y = rand() % it.get_height();
                int length = 3 + rand() % 3; // Random length between 3 and 5 pixels
                it.line(x, y, x - length, y + length, id(request_color));
            }
            it.image(it.get_width(), 0, id(micsatellite_small), ImageAlign::TOP_RIGHT); 
            it.printf((it.get_width() / 2), ((it.get_height() / 2)-10), id(font_response), id(init_color), TextAlign::CENTER, "Connecting to");
            it.printf((it.get_width() / 2), ((it.get_height() / 2)+10), id(font_response), id(init_color), TextAlign::CENTER, "Home Assistant");
     
      - id: status_page
        lambda: |-
          int spacing = 20;  // Define the spacing between lines
          int base_y = 25;    // Base y-coordinate
          auto font = id(font_status);
          auto color = id(status_color);
          int center_x = it.get_width() / 2;
          float memory_free_bytes = id(startup_memory_free).state;
          int memory_free_kb = static_cast<int>((memory_free_bytes / 1024.0) + 0.5);
          
          // Define the items to display
          std::vector<std::pair<std::string, std::string>> items = {
            {"Version:%s", std::string(id(project_version).state.c_str())},
            {"IP:%s", std::string(id(ip_address).state.c_str())},
            {"MAC:%s", std::string(id(wifi_mac_address).state.c_str())},
            {"Free Heap:%s KB", std::to_string(memory_free_kb)},
            {"MP:%s", std::string(id(mp_id).state.c_str()).substr(13)}
          };
          // Display the items
          for (size_t i = 0; i < items.size(); ++i) {
              it.printf(center_x, base_y + i * spacing, font, color, TextAlign::CENTER, items[i].first.c_str(), items[i].second.c_str());
          }

      - id: credits_page
        lambda: |-
          const char* title = "Thanks to:";
          int scroll_speed = 20;
          int num_contributors = id(contributors).size();
      
          // Define colors
          Color colors[] = {
            id(timer_color),
            id(response_color),
            id(error_color),
            id(init_color),
            id(status_color)
          };
          static const int num_colors = sizeof(colors) / sizeof(colors[0]);
      
          // Define fonts
          esphome::font::Font* fonts[] = {id(font_status), id(font_response), id(font_request)};
          static int font_index = 0;
      
          // Define screen dimensions
          int screen_width = it.get_width();
          int screen_height = it.get_height();
      
          // Define initial vertical offset to start from the bottom of the screen
          static int vertical_offset = 0;
      
          // Calculate dynamic y positions based on the font height and additional spacing
          int font_height = fonts[0]->get_height(); // Assuming all fonts have the same height
          int spacing = font_height + 5;
      
          // Pre-assign a color to each contributor
          static std::vector<Color> contributor_colors(num_contributors);
          static bool colors_assigned = false;
          if (!colors_assigned) {
            for (int i = 0; i < num_contributors; i++) {
              contributor_colors[i] = colors[rand() % num_colors];
            }
            colors_assigned = true;
          }
      
          // Draw the fixed text at the top
          int fixed_text_x = screen_width / 2;
          int fixed_text_y = screen_height - vertical_offset;
          it.print(fixed_text_x, fixed_text_y, fonts[font_index], id(request_color), TextAlign::CENTER, title);
          font_index = (font_index + 1) % 3; // Cycle through the fonts

          // Draw each contributor at fixed y positions with a vertical offset
          for (int i = 0; i < num_contributors; i++) {
            int text_x = screen_width / 2;
            int text_y = screen_height + (i + 1) * spacing - vertical_offset;
            it.print(text_x, text_y, fonts[font_index], contributor_colors[i], TextAlign::CENTER, id(contributors)[i].c_str());
            font_index = (font_index + 1) % 3; // Cycle through the fonts
          }
      
          // Update vertical offset
          vertical_offset += scroll_speed;
      
          // Reset vertical offset if all text has scrolled off the screen
          if (vertical_offset > screen_height + (num_contributors + 1) * spacing) {
            vertical_offset = 0;
          }

script:
  - id: convertto_multiline
    parameters:
      text: string
    then:
      - lambda: |
            std::string val = text;
            char* pch = strtok(&val[0], " ");         
            int line_count = 0;
            int current_line_length = 0;
            std::string current_line;
            std::vector<std::string> lines;
            
            while (pch != NULL) {
                int word_length = strlen(pch);
                if (current_line_length + word_length + 1 <= id(max_line_length)) {
                    if (!current_line.empty()) {
                        current_line += " ";
                        current_line_length++;
                    }
                    current_line += pch;
                    current_line_length += word_length;
                } else {
                    lines.push_back(current_line);
                    current_line = pch;
                    current_line_length = word_length;
                    line_count++;
                    if (line_count >= id(max_line_count)) {
                        break;
                    }
                }
                pch = strtok(NULL, " ");
            }
            
            if (!current_line.empty() && line_count < id(max_line_count)) {
                lines.push_back(current_line);
            }

            id(lines_array).clear();
            for (const auto& line : lines) {
                id(lines_array).push_back(line);
            }

  - id: play_alarm
    then: 
      - switch.turn_on: timer_ringing
      - lambda: id(voice_assistant_phase) = ${voice_assist_timer_finished_phase_id};
      - script.execute: draw_display
      - while:
          condition:
            switch.is_on: timer_ringing
          then:
            - homeassistant.service:
                service: media_player.play_media
                data:
                  entity_id: !lambda 'return id(mp_id).state.c_str();'
                  media_content_id: ${timer_sound_file}
                  media_content_type: "music"
                  announce: "true"
            - delay: 2s
      - switch.turn_off: timer_ringing
      - lambda: id(voice_assistant_phase) = ${voice_assist_idle_phase_id};
      - script.execute: draw_display
    
  - id: draw_display
    then:
      - if:
          condition:
            lambda: return !id(init_in_progress);
          then:
            - if:
                condition:
                  wifi.connected:
                then:
                  - if:
                      condition:
                        api.connected:
                      then:
                        - lambda: |
                            auto page_id = idle_page;
                            switch(id(voice_assistant_phase)) {
                              case ${voice_assist_listening_phase_id}:
                                page_id = listening_page;
                                break;
                              case ${voice_assist_thinking_phase_id}:
                                page_id = thinking_page;
                                break;
                              case ${voice_assist_replying_phase_id}:
                                page_id = replying_page;
                                break;
                              case ${voice_assist_error_phase_id}:
                                page_id = error_page;
                                break;
                              case ${voice_assist_not_ready_phase_id}:
                                page_id = no_ha_page;
                                break;
                              case ${voice_assist_timer_finished_phase_id}:
                                page_id = timer_finished_page;
                                break;
                              case ${voice_assist_credits_phase_id}:
                                page_id = credits_page;
                                break;
                              case ${voice_assist_status_phase_id}:
                                page_id = status_page;
                                break;
                              default:
                                page_id = idle_page;
                                break;
                            }
                            id(s3_lcd).show_page(page_id);
                            id(s3_lcd).update();
                      else:
                        - display.page.show: no_ha_page
                        - component.update: s3_lcd
                else:
                  - display.page.show: no_ha_page
                  - component.update: s3_lcd
          else:
            - display.page.show: initializing_page
            - component.update: s3_lcd